# Titanic Challenge
The [Kaggle challenge](https://www.kaggle.com/competitions/titanic) to train a model to predict survivors in the Titanic is an ongoing challenge. I participated and submitted various models. In the Jupyter Notebook you can find detailed strategies and models that I used.

the best model I used gave me a 0.80622 score, ranking me tied in the 330th spot out of 14468 total people who have attempted this problem, putting me in the top 2-3% of the overall score 


# The Mushroom Challenge
The [Kaggle challenge](https://www.kaggle.com/competitions/playground-series-s4e8) to train a model to recognize poisonous mushrooms is a challenge on Kaggle. In the Jupyter Notebook, I used an XGBoost model to gain a 98.4% accuracy, I decided to keep the NaN values on the training and testing data as there was a significant amount and, especially, very similar percentages between the training and testing data
